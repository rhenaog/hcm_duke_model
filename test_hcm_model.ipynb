{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import tqdm\n",
    "import scipy\n",
    "import os, os.path\n",
    "import pydicom as dicom\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import time\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "import torchvision\n",
    "from utils import save_checkpoint, load_checkpoint, save_metrics, load_metrics\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torchvideo.transforms as VT\n",
    "from cv2 import resize\n",
    "import cv2\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "from data_loader_hcm import load_video_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([15.890775, 48.323906, 48.834034])\n",
    "std = np.array([33.840668, 62.168327, 62.729694])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "period =1\n",
    "length = 16\n",
    "spatial_dim = (112, 112)\n",
    "#target_video_shape = (228, 288)\n",
    "frame_perm=False\n",
    "jitter_ratio = 0.5\n",
    "train_transform = transform=transforms.Compose([\n",
    "    VT.PILVideoToTensor(ordering='TCHW'),\n",
    "    ])\n",
    "\n",
    "\n",
    "train_val_test_flag = 'test'\n",
    "valid_dataset = load_video_data(\n",
    "    train_val_test_flag = train_val_test_flag,   \n",
    "    mean = mean, std = std,\n",
    "    noise = None,\n",
    "    length=length,\n",
    "    min_len = length,\n",
    "    max_len = length,\n",
    "    period = period,\n",
    "    select_channel = None,\n",
    "    frame_perm = False,\n",
    "    spatial_dim = spatial_dim,\n",
    "    give_me_all_clips = True,\n",
    "    device=device)\n",
    "\n",
    "print(\"Test num {}\".format(len(test_dataset)))\n",
    "\n",
    "# dataloader\n",
    "test_batch_size = 1\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = torchvision.models.video.r2plus1d_18(pretrained=True)\n",
    "device = torch.device(\"cuda\")\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.module.fc = nn.Linear(in_features=model.module.fc.in_features, out_features=2, bias=True)\n",
    "\n",
    "model_dir = '/model_dir/'\n",
    "load_checkpoint(os.path.join(model_dir,'best_epoch.pt'), model)\n",
    "\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "top_cut = 20\n",
    "bottom_cut = 90\n",
    "right_cut = 30\n",
    "left_cut = 90\n",
    "target_size = (112,112)\n",
    "with torch.no_grad():\n",
    "\n",
    "    # validation loop view level\n",
    "    print(\"Begin Test\")\n",
    "    valid_sample_count = 0.0\n",
    "    valid_running_loss = 0.0\n",
    "    valid_running_acc = 0.0\n",
    "    valid_labels = []\n",
    "    valid_outputs = []\n",
    "    valid_logits = []\n",
    "    all_logits = []\n",
    "    # video_path_list = []\n",
    "    ground_truth_list = []\n",
    "    for videos, frame_nums, labels  in tqdm.tqdm(test_dataloader):\n",
    "        videos = videos.type(torch.FloatTensor).to(device)\n",
    "        frame_nums = frame_nums.type(torch.LongTensor).to(device)\n",
    "        labels = labels.type(torch.LongTensor).to(device)\n",
    "\n",
    "        loop_num = int(np.floor(frame_nums.data.cpu().numpy()/16))\n",
    "        sub_output = []\n",
    "        sub_logits = []\n",
    "        for i in range(loop_num):\n",
    "            video_sub = videos[:,:,16*i:16*(i+1),:,:]\n",
    "            cropped_img = []\n",
    "            for i in range(video_sub.shape[0]):\n",
    "                new_data = video_sub[i,:,:,top_cut:bottom_cut,right_cut:left_cut]\n",
    "                new_data = new_data.permute(1, 0, 2, 3)\n",
    "                resized_swapped_tensor = F.interpolate(new_data, size=target_size, mode='bicubic', align_corners=False)\n",
    "                resized_tensor = resized_swapped_tensor.permute(1, 0, 2, 3)\n",
    "                resized_tensor = torch.unsqueeze(resized_tensor,0)\n",
    "            cropped_img.append(resized_tensor)\n",
    "            cropped_img = torch.cat(cropped_img,dim=0)\n",
    "        \n",
    "            output = model(cropped_img)\n",
    "            logits = F.softmax(output,dim=1)\n",
    "            sub_logits.append(logits)\n",
    "            sub_output.append(output)\n",
    "\n",
    "\n",
    "\n",
    "        labels = labels.reshape(-1,1)\n",
    "\n",
    "        max_out = torch.mean(torch.cat(sub_output,dim=0),dim=0)\n",
    "        max_logits = torch.mean(torch.cat(sub_logits,dim=0),dim=0)\n",
    "        weighted_out = max_logits[1]\n",
    "\n",
    "\n",
    "        valid_labels.append(labels)\n",
    "        valid_outputs.append(weighted_out)\n",
    "        valid_logits.append(F.softmax(max_out)[1])\n",
    "\n",
    "\n",
    "        pred_labels = weighted_out >= 0.5\n",
    "        pred_labels = pred_labels.int()\t\t\t\n",
    "\n",
    "        ground_truth_list.append(labels.cpu())\t\n",
    "        all_logits.append(weighted_out.detach().cpu().numpy())\n",
    "\n",
    "        valid_sample_count += labels.shape[0]\n",
    "        valid_running_acc += (pred_labels == labels).sum().item()\n",
    "\n",
    "\n",
    "valid_labels = torch.cat(valid_labels, dim=0)\n",
    "\n",
    "valid_outputs = torch.stack(valid_outputs, dim=0)\n",
    "valid_logits = torch.stack(valid_logits,dim=0)\n",
    "\n",
    "valid_outputs_np = valid_outputs.cpu().data.numpy()\n",
    "valid_labels_np = valid_labels.cpu().data.numpy()\n",
    "\n",
    "\n",
    "label = np.concatenate(ground_truth_list).ravel()\n",
    "fpr, tpr, thresh = metrics.roc_curve(valid_labels_np,valid_outputs_np)\n",
    "test_auc = metrics.auc(fpr,tpr) \n",
    "\n",
    "print(test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test_results_dir = '/model_test_results_dir/'\n",
    "np.save(os.path.join(model_test_results_dir, 'hcm_output_test.npy'), valid_outputs.cpu().data.numpy())\n",
    "np.save(os.path.join(model_test_results_dir, 'hcm_logits_test.npy'), valid_logits.cpu().data.numpy())\n",
    "np.save(os.path.join(model_test_results_dir, 'hcm_labels_test.npy'), valid_labels.cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hcm_outputs = np.load(os.path.join(model_test_results_dir, 'hcm_output_test.npy'))\n",
    "hcm_logits = np.load(os.path.join(model_test_results_dir, 'hcm_logits_test.npy'))\n",
    "hcm_labels = np.load(os.path.join(model_test_results_dir, 'hcm_labels_test.npy'))\n",
    "\n",
    "valid_outputs_np = hcm_outputs\n",
    "valid_labels_np = hcm_labels\n",
    "video_data_list = []\n",
    "\n",
    "cases_path = '/data/cases_test_list.csv'\n",
    "with open(cases_path, 'r') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        video_data_list.append(row[0])\n",
    "\n",
    "        \n",
    "controls_path = '/data/controls_test_list.csv'\n",
    "with open(controls_path, 'r') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        video_data_list.append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_labels_np = hcm_labels\n",
    "valid_outputs_np = hcm_outputs\n",
    "study_level_prediction = {}\n",
    "num_views = 0\n",
    "case_count = 0\n",
    "cases_list = []\n",
    "for idx, e_data in enumerate(video_data_list): # validation list\n",
    "    study_name = e_data.split('/')[-1].split('_')[0]\n",
    "    if valid_labels_np[idx] == 0:\n",
    "        study_name = \"/data/hcm/\" + study_name\n",
    "    else:\n",
    "        study_name = \"/data/hcm/cases/\" + study_name\n",
    "        cases_list.append(study_name)\n",
    "    if study_name not in study_level_prediction:\n",
    "        study_level_prediction[study_name] = ([], [], valid_labels_np[idx])\n",
    "        study_level_prediction[study_name][0].append(valid_outputs_np[idx])\n",
    "    else:\n",
    "        study_level_prediction[study_name][0].append(valid_outputs_np[idx])\n",
    "        assert study_level_prediction[study_name][2] == valid_labels_np[idx]\n",
    "\n",
    "study_level_prediction_list = []\n",
    "study_level_prediction_label = []\n",
    "\n",
    "for e_study in study_level_prediction:\n",
    "    preds = study_level_prediction[e_study][0]\n",
    "    view_prob = study_level_prediction[e_study][1]\n",
    "    study_pred = np.zeros(1)\n",
    "    view_count = 0\n",
    "    for i in range(len(preds)):\n",
    "        study_pred += preds[i]\n",
    "    study_pred = study_pred/len(preds)\n",
    "    study_level_prediction_list.append(study_pred)\n",
    "    study_level_prediction_label.append(study_level_prediction[e_study][2])\n",
    "        \n",
    "study_level_prediction_list = np.vstack(study_level_prediction_list)\n",
    "study_level_prediction_label = np.array(study_level_prediction_label)\t\t\n",
    "\n",
    "fpr, tpr, thresh = metrics.roc_curve(study_level_prediction_label,study_level_prediction_list)\n",
    "test_study_auc = metrics.auc(fpr,tpr) \n",
    "print(test_study_auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
